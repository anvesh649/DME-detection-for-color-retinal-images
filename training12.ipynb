{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "environment": {
      "name": "tf2-gpu.2-4.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "dme.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ff105a",
        "outputId": "9aa8c6dd-57de-44d2-b16a-b542b31eced0"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy import std, mean, sqrt, max, min, exp\n",
        "\n",
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "# Color Transormation\n",
        "def ColorTransition(Simg, Timg):\n",
        "    R, G, B=cv2.split(Simg)\n",
        "    R = np.float64(R)\n",
        "    G = np.float64(G)\n",
        "    B = np.float64(B)\n",
        " \n",
        "    R1, G1, B1=cv2.split(Timg)\n",
        "    R1 = np.float64(R1)\n",
        "    G1 = np.float64(G1)\n",
        "    B1 = np.float64(B1)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Source Image\n",
        "    L=0.3811*R+0.5783*G+0.0402*B;\n",
        "    M=0.1967*R+0.7244*G+0.0782*B;\n",
        "    S=0.0241*R+0.1288*G+0.8444*B;\n",
        "    L = np.float64(L)\n",
        "    M = np.float64(M)\n",
        "    S = np.float64(S)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Target Image\n",
        "    L1=0.3811*R1+0.5783*G1+0.0402*B1;\n",
        "    M1=0.1967*R1+0.7244*G1+0.0782*B1;\n",
        "    S1=0.0241*R1+0.1288*G1+0.8444*B1;\n",
        "    L1 = np.float64(L1)\n",
        "    M1 = np.float64(M1)\n",
        "    S1 = np.float64(S1)\n",
        " \n",
        "    I2 = cv2.merge((L,M,S))\n",
        "    A2 = cv2.merge((L1,M1,S1))\n",
        "    \n",
        "    l=0.5774*L+0.5774*M+0.5774*S;\n",
        "    a=0.4082*L+0.4082*M-0.8165*S;\n",
        "    b=0.7071*L-0.7071*M;\n",
        "    l = np.float64(l)\n",
        "    a = np.float64(a)\n",
        "    b = np.float64(b)\n",
        " \n",
        "    l1=0.5774*L1+0.5774*M1+0.5774*S1;\n",
        "    a1=0.4082*L1+0.4082*M1-0.8165*S1;\n",
        "    b1=0.7071*L1-0.7071*M1;\n",
        "    l1 = np.float64(l1)\n",
        "    a1 = np.float64(a1)\n",
        "    b1 = np.float64(b1)\n",
        " \n",
        "    I3 = cv2.merge((l,a,b))\n",
        "    A3 = cv2.merge((l1,a1,b1))\n",
        " \n",
        "    std1=std(l1);\n",
        "    std2=std(l);\n",
        " \n",
        "    std3=std(a1);\n",
        "    std4=std(a);\n",
        "    \n",
        "    std5=std(b1);\n",
        "    std6=std(b);\n",
        " \n",
        "    p=(sqrt(mean(l1))-(sqrt(mean(l))))/(sqrt(mean(l1))+(sqrt(mean(l))));   \n",
        "    s=0\n",
        "    if p>0:    \n",
        "        s=0.9-(0.9 - 0.15)/(1+exp((p-0.45)/(0.05)));\n",
        "    else:\n",
        "        s=0.15;\n",
        " \n",
        "    l2=mean(mean(l1))+(l-mean(mean(l)))*(1+s);\n",
        "    a2=mean(mean(a1))+(a-mean(mean(a)));\n",
        "    b2=mean(mean(b1))+(b-mean(mean(b)));\n",
        "    l2 = np.float64(l2)\n",
        "    a2 = np.float64(a2)\n",
        "    b2 = np.float64(b2)\n",
        " \n",
        "    l3=mean(mean(l1))+(l-mean(mean(l)))*(std1/std2);\n",
        "    a3=mean(mean(a1))+(a-mean(mean(a)))*(std3/std4);\n",
        "    b3=mean(mean(b1))+(b-mean(mean(b)))*(std5/std6);\n",
        "    l3 = np.float64(l3)\n",
        "    a3 = np.float64(a3)\n",
        "    b3 = np.float64(b3)\n",
        " \n",
        "    max_l=max(l2);\n",
        "    min_l=min(l2);\n",
        "    max_a=max(a2);\n",
        "    min_a=min(a2);\n",
        "    max_b=max(b2);\n",
        "    min_b=min(b2);\n",
        "  \n",
        "    I4 = cv2.merge((l2,a2,b2))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L2=0.5774*l2+0.4082*a2+0.7071*b2;\n",
        "    M2=0.5774*l2+0.4082*a2-0.7071*b2;\n",
        "    S2=0.5774*l2-0.8169*a2;\n",
        "    L2 = np.float64(L2)\n",
        "    M2 = np.float64(M2)\n",
        "    S2 = np.float64(S2)\n",
        " \n",
        "    R2=4.4679*L2-3.5873*M2+0.1193*S2;\n",
        "    G2=-1.2186*L2+2.3809*M2-0.1624*S2;\n",
        "    B2=0.0497*L2-0.2439*M2+1.2045*S2;\n",
        " \n",
        "    I5 = cv2.merge((R1, G2, B2))\n",
        "    I6 = cv2.merge((l3,a3,b3))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L3=0.5774*l3+0.4082*a3+0.7071*b3;\n",
        "    M3=0.5774*l3+0.4082*a3-0.7071*b3;\n",
        "    S3=0.5774*l3-0.8169*a3;\n",
        "    L3 = np.float64(L3)\n",
        "    M3 = np.float64(M3)\n",
        "    S3 = np.float64(S3)\n",
        " \n",
        "    R3=4.4679*L3-3.5873*M3+0.1193*S3;\n",
        "    G3=-1.2186*L3+2.3809*M3-0.1624*S3;\n",
        "    B3=0.0497*L3-0.2439*M3+1.2045*S3;\n",
        "    # R3 = np.float64(R3)\n",
        "    # G3 = np.float64(G3)\n",
        "    # B3 = np.float64(B3)\n",
        " \n",
        "    I7 = cv2.merge((R3,G3,B3))\n",
        "    I7 = normalize(I7)\n",
        "    return I7\n",
        "\n",
        "\n",
        "def preProcessing(img):\n",
        "    # Target = cv2.imread(train_path+'/0/IDRiD_061.jpg')\n",
        "    Target = cv2.imread('20051020_45137_0100_PP.tif')\n",
        "    Target = cv2.cvtColor(Target, cv2.COLOR_BGR2RGB)\n",
        "    Target = cv2.resize(Target, (400, 400))\n",
        "   # print(filename)\n",
        "   # img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = ColorTransition(img, Target)\n",
        "    img = normalize(img)\n",
        "    return img\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers, activations\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "print(\"Done Importing\")\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    image_gen=ImageDataGenerator(\n",
        "        zca_epsilon=1e-06,\n",
        "        rotation_range=80,\n",
        "        width_shift_range=2.0,\n",
        "        height_shift_range=2.0,\n",
        "        brightness_range=None,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.3,\n",
        "        channel_shift_range=0.0,\n",
        "        fill_mode=\"nearest\",\n",
        "        cval=0.0,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        rescale=2,\n",
        "        preprocessing_function=preProcessing)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    train=image_gen.flow_from_directory(\"TrainSet\",\n",
        "                                        target_size=(400, 400),\n",
        "                                        batch_size=16,\n",
        "                                        class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "    test=image_gen.flow_from_directory(\"TestSet\",\n",
        "                                       target_size=(400, 400),\n",
        "                                        batch_size=8,\n",
        "                                        class_mode=\"categorical\")\n",
        "\n",
        "    ir2=InceptionResNetV2(include_top=False, input_shape=(400, 400, 3))\n",
        "    print(\"Model Imported!\")\n",
        "    output = ir2.layers[-1].output\n",
        "    output = keras.layers.Flatten()(output)\n",
        "    ir2_model = Model(ir2.input, output)\n",
        "    count=0\n",
        "\n",
        "    for layer in ir2_model.layers:\n",
        "            if(count>400):\n",
        "                break\n",
        "            layer.trainable=False\n",
        "            count+=1\n",
        "\n",
        "    model= Sequential()\n",
        "    model.add(ir2_model)\n",
        "\n",
        "    model.add(Dense(512, activation='relu',input_dim=ir2_model.output_shape[1]))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(Dense(32))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "   \n"
      ],
      "id": "52ff105a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Importing\n",
            "Found 1613 images belonging to 2 classes.\n",
            "Found 103 images belonging to 2 classes.\n",
            "Model Imported!\n",
            "Epoch 1/70\n",
            "101/101 [==============================] - 255s 2s/step - loss: 2.0086 - accuracy: 0.6143 - val_loss: 201702.8906 - val_accuracy: 0.5437\n",
            "Epoch 2/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.5834 - accuracy: 0.7193 - val_loss: 0.9055 - val_accuracy: 0.5049\n",
            "Epoch 3/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.5812 - accuracy: 0.7217 - val_loss: 0.7753 - val_accuracy: 0.4078\n",
            "Epoch 4/70\n",
            "101/101 [==============================] - 241s 2s/step - loss: 0.5760 - accuracy: 0.7181 - val_loss: 1.0272 - val_accuracy: 0.4369\n",
            "Epoch 5/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.5412 - accuracy: 0.7773 - val_loss: 9.2614 - val_accuracy: 0.5728\n",
            "Epoch 6/70\n",
            "101/101 [==============================] - 239s 2s/step - loss: 0.4426 - accuracy: 0.8408 - val_loss: 0.5413 - val_accuracy: 0.7476\n",
            "Epoch 7/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.3631 - accuracy: 0.8751 - val_loss: 0.4186 - val_accuracy: 0.7961\n",
            "Epoch 8/70\n",
            "101/101 [==============================] - 238s 2s/step - loss: 0.3089 - accuracy: 0.8972 - val_loss: 0.4031 - val_accuracy: 0.8350\n",
            "Epoch 9/70\n",
            "101/101 [==============================] - 236s 2s/step - loss: 0.3122 - accuracy: 0.8838 - val_loss: 0.5031 - val_accuracy: 0.7864\n",
            "Epoch 10/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.3215 - accuracy: 0.8876 - val_loss: 0.4206 - val_accuracy: 0.8350\n",
            "Epoch 11/70\n",
            "101/101 [==============================] - 238s 2s/step - loss: 0.3173 - accuracy: 0.8831 - val_loss: 0.5318 - val_accuracy: 0.7864\n",
            "Epoch 12/70\n",
            "101/101 [==============================] - 236s 2s/step - loss: 0.3212 - accuracy: 0.8819 - val_loss: 0.4421 - val_accuracy: 0.8058\n",
            "Epoch 13/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2828 - accuracy: 0.8879 - val_loss: 0.5740 - val_accuracy: 0.7767\n",
            "Epoch 14/70\n",
            "101/101 [==============================] - 239s 2s/step - loss: 0.2842 - accuracy: 0.8945 - val_loss: 0.4849 - val_accuracy: 0.7767\n",
            "Epoch 15/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2551 - accuracy: 0.9086 - val_loss: 0.4177 - val_accuracy: 0.8544\n",
            "Epoch 16/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2446 - accuracy: 0.9077 - val_loss: 0.4133 - val_accuracy: 0.8447\n",
            "Epoch 17/70\n",
            "101/101 [==============================] - 238s 2s/step - loss: 0.2617 - accuracy: 0.9027 - val_loss: 0.4348 - val_accuracy: 0.7961\n",
            "Epoch 18/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2390 - accuracy: 0.9075 - val_loss: 0.5019 - val_accuracy: 0.7864\n",
            "Epoch 19/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2363 - accuracy: 0.9128 - val_loss: 0.4580 - val_accuracy: 0.8447\n",
            "Epoch 20/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.2210 - accuracy: 0.9059 - val_loss: 0.3455 - val_accuracy: 0.8544\n",
            "Epoch 21/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.2405 - accuracy: 0.9246 - val_loss: 0.3797 - val_accuracy: 0.8544\n",
            "Epoch 22/70\n",
            "101/101 [==============================] - 241s 2s/step - loss: 0.2137 - accuracy: 0.9168 - val_loss: 0.5305 - val_accuracy: 0.7767\n",
            "Epoch 23/70\n",
            "101/101 [==============================] - 241s 2s/step - loss: 0.2190 - accuracy: 0.9166 - val_loss: 0.4123 - val_accuracy: 0.8447\n",
            "Epoch 24/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2186 - accuracy: 0.9189 - val_loss: 0.7768 - val_accuracy: 0.8058\n",
            "Epoch 25/70\n",
            "101/101 [==============================] - 239s 2s/step - loss: 0.2399 - accuracy: 0.9104 - val_loss: 0.3589 - val_accuracy: 0.8544\n",
            "Epoch 26/70\n",
            "101/101 [==============================] - 241s 2s/step - loss: 0.2077 - accuracy: 0.9264 - val_loss: 0.5523 - val_accuracy: 0.8350\n",
            "Epoch 27/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.2163 - accuracy: 0.9219 - val_loss: 0.5125 - val_accuracy: 0.8350\n",
            "Epoch 28/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.1978 - accuracy: 0.9295 - val_loss: 0.4889 - val_accuracy: 0.8155\n",
            "Epoch 29/70\n",
            "101/101 [==============================] - 239s 2s/step - loss: 0.2295 - accuracy: 0.9171 - val_loss: 0.3520 - val_accuracy: 0.8641\n",
            "Epoch 30/70\n",
            "101/101 [==============================] - 238s 2s/step - loss: 0.1822 - accuracy: 0.9376 - val_loss: 0.4025 - val_accuracy: 0.8641\n",
            "Epoch 31/70\n",
            "101/101 [==============================] - 238s 2s/step - loss: 0.2157 - accuracy: 0.9249 - val_loss: 0.4322 - val_accuracy: 0.8447\n",
            "Epoch 32/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.1914 - accuracy: 0.9245 - val_loss: 0.4866 - val_accuracy: 0.8252\n",
            "Epoch 33/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.2262 - accuracy: 0.9208 - val_loss: 0.7164 - val_accuracy: 0.8058\n",
            "Epoch 34/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.2035 - accuracy: 0.9181 - val_loss: 0.9356 - val_accuracy: 0.7767\n",
            "Epoch 35/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.2088 - accuracy: 0.9183 - val_loss: 0.6962 - val_accuracy: 0.7961\n",
            "Epoch 36/70\n",
            "101/101 [==============================] - 240s 2s/step - loss: 0.1950 - accuracy: 0.9293 - val_loss: 0.5434 - val_accuracy: 0.8738\n",
            "Epoch 37/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.2018 - accuracy: 0.9213 - val_loss: 0.8785 - val_accuracy: 0.7864\n",
            "Epoch 38/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.1942 - accuracy: 0.9269 - val_loss: 0.4061 - val_accuracy: 0.8058\n",
            "Epoch 39/70\n",
            "101/101 [==============================] - 236s 2s/step - loss: 0.1946 - accuracy: 0.9279 - val_loss: 0.5757 - val_accuracy: 0.8058\n",
            "Epoch 40/70\n",
            "101/101 [==============================] - 239s 2s/step - loss: 0.1849 - accuracy: 0.9373 - val_loss: 0.5618 - val_accuracy: 0.8544\n",
            "Epoch 41/70\n",
            "101/101 [==============================] - 242s 2s/step - loss: 0.1759 - accuracy: 0.9389 - val_loss: 0.4332 - val_accuracy: 0.8350\n",
            "Epoch 49/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.2173 - accuracy: 0.9108 - val_loss: 0.5245 - val_accuracy: 0.8544\n",
            "Epoch 50/70\n",
            "101/101 [==============================] - 244s 2s/step - loss: 0.1815 - accuracy: 0.9269 - val_loss: 0.6898 - val_accuracy: 0.8252\n",
            "Epoch 51/70\n",
            "101/101 [==============================] - 243s 2s/step - loss: 0.1922 - accuracy: 0.9203 - val_loss: 0.5996 - val_accuracy: 0.8447\n",
            "Epoch 52/70\n",
            "101/101 [==============================] - 239s 2s/step - loss: 0.1468 - accuracy: 0.9396 - val_loss: 0.6994 - val_accuracy: 0.8058\n",
            "Epoch 53/70\n",
            "101/101 [==============================] - 238s 2s/step - loss: 0.1463 - accuracy: 0.9466 - val_loss: 0.5296 - val_accuracy: 0.8155\n",
            "Epoch 54/70\n",
            "101/101 [==============================] - 244s 2s/step - loss: 0.1614 - accuracy: 0.9348 - val_loss: 0.7345 - val_accuracy: 0.7961\n",
            "Epoch 55/70\n",
            " 14/101 [===>..........................] - ETA: 3:10 - loss: 0.1265 - accuracy: 0.9673"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-be1b912fb64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0119a8bb",
        "outputId": "54d735b9-caf2-41e5-fe44-3979e9fbdba7"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"best.h5\",\n",
        "    save_weights_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "    \n",
        "results=model.fit(train,epochs=30,validation_data=test, callbacks=[model_checkpoint_callback])"
      ],
      "id": "0119a8bb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1586 - accuracy: 0.9411 - val_loss: 0.3825 - val_accuracy: 0.8544\n",
            "Epoch 2/30\n",
            "101/101 [==============================] - 279s 3s/step - loss: 0.1454 - accuracy: 0.9479 - val_loss: 0.6480 - val_accuracy: 0.8058\n",
            "Epoch 3/30\n",
            "101/101 [==============================] - 229s 2s/step - loss: 0.1626 - accuracy: 0.9405 - val_loss: 0.6751 - val_accuracy: 0.8447\n",
            "Epoch 4/30\n",
            "101/101 [==============================] - 236s 2s/step - loss: 0.1348 - accuracy: 0.9523 - val_loss: 0.9754 - val_accuracy: 0.8350\n",
            "Epoch 5/30\n",
            "101/101 [==============================] - 231s 2s/step - loss: 0.1690 - accuracy: 0.9374 - val_loss: 0.4544 - val_accuracy: 0.8447\n",
            "Epoch 6/30\n",
            "101/101 [==============================] - 230s 2s/step - loss: 0.2021 - accuracy: 0.9293 - val_loss: 0.6273 - val_accuracy: 0.8447\n",
            "Epoch 7/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1929 - accuracy: 0.9392 - val_loss: 1.3959 - val_accuracy: 0.8058\n",
            "Epoch 8/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1474 - accuracy: 0.9448 - val_loss: 0.5838 - val_accuracy: 0.7767\n",
            "Epoch 9/30\n",
            "101/101 [==============================] - 229s 2s/step - loss: 0.1676 - accuracy: 0.9436 - val_loss: 0.7118 - val_accuracy: 0.8058\n",
            "Epoch 10/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1516 - accuracy: 0.9442 - val_loss: 0.5445 - val_accuracy: 0.8058\n",
            "Epoch 11/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1245 - accuracy: 0.9535 - val_loss: 0.7088 - val_accuracy: 0.8155\n",
            "Epoch 12/30\n",
            "101/101 [==============================] - 234s 2s/step - loss: 0.1497 - accuracy: 0.9442 - val_loss: 1.2142 - val_accuracy: 0.8641\n",
            "Epoch 13/30\n",
            "101/101 [==============================] - 259s 3s/step - loss: 0.1410 - accuracy: 0.9504 - val_loss: 0.9940 - val_accuracy: 0.7573\n",
            "Epoch 14/30\n",
            "101/101 [==============================] - 229s 2s/step - loss: 0.1169 - accuracy: 0.9572 - val_loss: 0.4821 - val_accuracy: 0.7961\n",
            "Epoch 15/30\n",
            "101/101 [==============================] - 235s 2s/step - loss: 0.1164 - accuracy: 0.9585 - val_loss: 0.7054 - val_accuracy: 0.8252\n",
            "Epoch 16/30\n",
            "101/101 [==============================] - 231s 2s/step - loss: 0.1327 - accuracy: 0.9485 - val_loss: 0.5234 - val_accuracy: 0.8350\n",
            "Epoch 17/30\n",
            "101/101 [==============================] - 234s 2s/step - loss: 0.1260 - accuracy: 0.9516 - val_loss: 0.7828 - val_accuracy: 0.8155\n",
            "Epoch 18/30\n",
            "101/101 [==============================] - 233s 2s/step - loss: 0.1268 - accuracy: 0.9473 - val_loss: 0.5816 - val_accuracy: 0.7767\n",
            "Epoch 19/30\n",
            "101/101 [==============================] - 230s 2s/step - loss: 0.1191 - accuracy: 0.9603 - val_loss: 0.7151 - val_accuracy: 0.8058\n",
            "Epoch 20/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1209 - accuracy: 0.9516 - val_loss: 0.4159 - val_accuracy: 0.8350\n",
            "Epoch 21/30\n",
            "101/101 [==============================] - 233s 2s/step - loss: 0.1298 - accuracy: 0.9504 - val_loss: 0.3989 - val_accuracy: 0.8350\n",
            "Epoch 22/30\n",
            "101/101 [==============================] - 234s 2s/step - loss: 0.1017 - accuracy: 0.9628 - val_loss: 0.9501 - val_accuracy: 0.7864\n",
            "Epoch 23/30\n",
            "101/101 [==============================] - 232s 2s/step - loss: 0.1274 - accuracy: 0.9535 - val_loss: 0.7036 - val_accuracy: 0.7767\n",
            "Epoch 24/30\n",
            "101/101 [==============================] - 231s 2s/step - loss: 0.1329 - accuracy: 0.9585 - val_loss: 1.0649 - val_accuracy: 0.6311\n",
            "Epoch 25/30\n",
            "101/101 [==============================] - 231s 2s/step - loss: 0.1195 - accuracy: 0.9535 - val_loss: 0.5548 - val_accuracy: 0.8252\n",
            "Epoch 26/30\n",
            "101/101 [==============================] - 235s 2s/step - loss: 0.1042 - accuracy: 0.9597 - val_loss: 1.3720 - val_accuracy: 0.7961\n",
            "Epoch 27/30\n",
            "101/101 [==============================] - 234s 2s/step - loss: 0.1293 - accuracy: 0.9529 - val_loss: 0.7850 - val_accuracy: 0.8252\n",
            "Epoch 28/30\n",
            "101/101 [==============================] - 233s 2s/step - loss: 0.1012 - accuracy: 0.9671 - val_loss: 0.7366 - val_accuracy: 0.7961\n",
            "Epoch 29/30\n",
            "101/101 [==============================] - 231s 2s/step - loss: 0.1184 - accuracy: 0.9535 - val_loss: 0.6534 - val_accuracy: 0.8252\n",
            "Epoch 30/30\n",
            "101/101 [==============================] - 234s 2s/step - loss: 0.1207 - accuracy: 0.9603 - val_loss: 0.5502 - val_accuracy: 0.8155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b831350b",
        "outputId": "d8989f38-a983-4e23-8ca3-c7b2791cb0f3"
      },
      "source": [
        " print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
      ],
      "id": "b831350b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885f7e53"
      },
      "source": [
        ""
      ],
      "id": "885f7e53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ceb9ec7"
      },
      "source": [
        ""
      ],
      "id": "7ceb9ec7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf71beaf"
      },
      "source": [
        ""
      ],
      "id": "bf71beaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f6f75ae"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers, activations\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2"
      ],
      "id": "6f6f75ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bf883fa"
      },
      "source": [
        ""
      ],
      "id": "0bf883fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bca4a93b"
      },
      "source": [
        ""
      ],
      "id": "bca4a93b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ca692bd"
      },
      "source": [
        ""
      ],
      "id": "3ca692bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc6d5bbd",
        "outputId": "bb700cf8-6053-42ad-a285-253635295a41"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy import std, mean, sqrt, max, min, exp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers, activations\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "print(\"Done Importing\")\n",
        "\n",
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "# Color Transormation\n",
        "def ColorTransition(Simg, Timg):\n",
        "    R, G, B=cv2.split(Simg)\n",
        "    R = np.float64(R)\n",
        "    G = np.float64(G)\n",
        "    B = np.float64(B)\n",
        " \n",
        "    R1, G1, B1=cv2.split(Timg)\n",
        "    R1 = np.float64(R1)\n",
        "    G1 = np.float64(G1)\n",
        "    B1 = np.float64(B1)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Source Image\n",
        "    L=0.3811*R+0.5783*G+0.0402*B;\n",
        "    M=0.1967*R+0.7244*G+0.0782*B;\n",
        "    S=0.0241*R+0.1288*G+0.8444*B;\n",
        "    L = np.float64(L)\n",
        "    M = np.float64(M)\n",
        "    S = np.float64(S)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Target Image\n",
        "    L1=0.3811*R1+0.5783*G1+0.0402*B1;\n",
        "    M1=0.1967*R1+0.7244*G1+0.0782*B1;\n",
        "    S1=0.0241*R1+0.1288*G1+0.8444*B1;\n",
        "    L1 = np.float64(L1)\n",
        "    M1 = np.float64(M1)\n",
        "    S1 = np.float64(S1)\n",
        " \n",
        "    I2 = cv2.merge((L,M,S))\n",
        "    A2 = cv2.merge((L1,M1,S1))\n",
        "    \n",
        "    l=0.5774*L+0.5774*M+0.5774*S;\n",
        "    a=0.4082*L+0.4082*M-0.8165*S;\n",
        "    b=0.7071*L-0.7071*M;\n",
        "    l = np.float64(l)\n",
        "    a = np.float64(a)\n",
        "    b = np.float64(b)\n",
        " \n",
        "    l1=0.5774*L1+0.5774*M1+0.5774*S1;\n",
        "    a1=0.4082*L1+0.4082*M1-0.8165*S1;\n",
        "    b1=0.7071*L1-0.7071*M1;\n",
        "    l1 = np.float64(l1)\n",
        "    a1 = np.float64(a1)\n",
        "    b1 = np.float64(b1)\n",
        " \n",
        "    I3 = cv2.merge((l,a,b))\n",
        "    A3 = cv2.merge((l1,a1,b1))\n",
        " \n",
        "    std1=std(l1);\n",
        "    std2=std(l);\n",
        " \n",
        "    std3=std(a1);\n",
        "    std4=std(a);\n",
        "    \n",
        "    std5=std(b1);\n",
        "    std6=std(b);\n",
        " \n",
        "    p=(sqrt(mean(l1))-(sqrt(mean(l))))/(sqrt(mean(l1))+(sqrt(mean(l))));   \n",
        "    s=0\n",
        "    if p>0:    \n",
        "        s=0.9-(0.9 - 0.15)/(1+exp((p-0.45)/(0.05)));\n",
        "    else:\n",
        "        s=0.15;\n",
        " \n",
        "    l2=mean(mean(l1))+(l-mean(mean(l)))*(1+s);\n",
        "    a2=mean(mean(a1))+(a-mean(mean(a)));\n",
        "    b2=mean(mean(b1))+(b-mean(mean(b)));\n",
        "    l2 = np.float64(l2)\n",
        "    a2 = np.float64(a2)\n",
        "    b2 = np.float64(b2)\n",
        " \n",
        "    l3=mean(mean(l1))+(l-mean(mean(l)))*(std1/std2);\n",
        "    a3=mean(mean(a1))+(a-mean(mean(a)))*(std3/std4);\n",
        "    b3=mean(mean(b1))+(b-mean(mean(b)))*(std5/std6);\n",
        "    l3 = np.float64(l3)\n",
        "    a3 = np.float64(a3)\n",
        "    b3 = np.float64(b3)\n",
        " \n",
        "    max_l=max(l2);\n",
        "    min_l=min(l2);\n",
        "    max_a=max(a2);\n",
        "    min_a=min(a2);\n",
        "    max_b=max(b2);\n",
        "    min_b=min(b2);\n",
        "  \n",
        "    I4 = cv2.merge((l2,a2,b2))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L2=0.5774*l2+0.4082*a2+0.7071*b2;\n",
        "    M2=0.5774*l2+0.4082*a2-0.7071*b2;\n",
        "    S2=0.5774*l2-0.8169*a2;\n",
        "    L2 = np.float64(L2)\n",
        "    M2 = np.float64(M2)\n",
        "    S2 = np.float64(S2)\n",
        " \n",
        "    R2=4.4679*L2-3.5873*M2+0.1193*S2;\n",
        "    G2=-1.2186*L2+2.3809*M2-0.1624*S2;\n",
        "    B2=0.0497*L2-0.2439*M2+1.2045*S2;\n",
        " \n",
        "    I5 = cv2.merge((R1, G2, B2))\n",
        "    I6 = cv2.merge((l3,a3,b3))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L3=0.5774*l3+0.4082*a3+0.7071*b3;\n",
        "    M3=0.5774*l3+0.4082*a3-0.7071*b3;\n",
        "    S3=0.5774*l3-0.8169*a3;\n",
        "    L3 = np.float64(L3)\n",
        "    M3 = np.float64(M3)\n",
        "    S3 = np.float64(S3)\n",
        " \n",
        "    R3=4.4679*L3-3.5873*M3+0.1193*S3;\n",
        "    G3=-1.2186*L3+2.3809*M3-0.1624*S3;\n",
        "    B3=0.0497*L3-0.2439*M3+1.2045*S3;\n",
        "    # R3 = np.float64(R3)\n",
        "    # G3 = np.float64(G3)\n",
        "    # B3 = np.float64(B3)\n",
        " \n",
        "    I7 = cv2.merge((R3,G3,B3))\n",
        "    I7 = normalize(I7)\n",
        "    return I7\n",
        "\n",
        "\n",
        "def preProcessing(img):\n",
        "    # Target = cv2.imread(train_path+'/0/IDRiD_061.jpg')\n",
        "    Target = cv2.imread('20051020_45137_0100_PP.tif')\n",
        "    Target = cv2.cvtColor(Target, cv2.COLOR_BGR2RGB)\n",
        "    Target = cv2.resize(Target, (400, 400))\n",
        "    img = ColorTransition(img, Target)\n",
        "    img = normalize(img)\n",
        "    return img"
      ],
      "id": "dc6d5bbd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Importing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aabc3c51"
      },
      "source": [
        ""
      ],
      "id": "aabc3c51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "227fae66",
        "outputId": "7d59b7c8-9a60-480c-a288-951db786792e"
      },
      "source": [
        ""
      ],
      "id": "227fae66",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Importing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abb21d68"
      },
      "source": [
        "    "
      ],
      "id": "abb21d68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dce2517"
      },
      "source": [
        ""
      ],
      "id": "6dce2517",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26b8e8a1",
        "outputId": "610bf13c-d526-4e56-e3c2-a1cf254898fb"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"bestk.h5\",\n",
        "        save_weights_only=False,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "\n",
        "    results=model.fit(train,epochs=100,validation_data=test, callbacks=[model_checkpoint_callback])"
      ],
      "id": "26b8e8a1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": " No algorithm worked!\n\t [[node model_13/conv2d_2639/Conv2D (defined at <ipython-input-25-94987ef38e57>:10) ]] [Op:__inference_train_function_420352]\n\nFunction call stack:\ntrain_function\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-94987ef38e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         save_best_only=True)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m:  No algorithm worked!\n\t [[node model_13/conv2d_2639/Conv2D (defined at <ipython-input-25-94987ef38e57>:10) ]] [Op:__inference_train_function_420352]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4023084",
        "outputId": "741e6656-2c82-4a31-c015-132756fa075d"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy import std, mean, sqrt, max, min, exp\n",
        "\n",
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "# Color Transormation\n",
        "def ColorTransition(Simg, Timg):\n",
        "    R, G, B=cv2.split(Simg)\n",
        "    R = np.float64(R)\n",
        "    G = np.float64(G)\n",
        "    B = np.float64(B)\n",
        " \n",
        "    R1, G1, B1=cv2.split(Timg)\n",
        "    R1 = np.float64(R1)\n",
        "    G1 = np.float64(G1)\n",
        "    B1 = np.float64(B1)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Source Image\n",
        "    L=0.3811*R+0.5783*G+0.0402*B;\n",
        "    M=0.1967*R+0.7244*G+0.0782*B;\n",
        "    S=0.0241*R+0.1288*G+0.8444*B;\n",
        "    L = np.float64(L)\n",
        "    M = np.float64(M)\n",
        "    S = np.float64(S)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Target Image\n",
        "    L1=0.3811*R1+0.5783*G1+0.0402*B1;\n",
        "    M1=0.1967*R1+0.7244*G1+0.0782*B1;\n",
        "    S1=0.0241*R1+0.1288*G1+0.8444*B1;\n",
        "    L1 = np.float64(L1)\n",
        "    M1 = np.float64(M1)\n",
        "    S1 = np.float64(S1)\n",
        " \n",
        "    I2 = cv2.merge((L,M,S))\n",
        "    A2 = cv2.merge((L1,M1,S1))\n",
        "    \n",
        "    l=0.5774*L+0.5774*M+0.5774*S;\n",
        "    a=0.4082*L+0.4082*M-0.8165*S;\n",
        "    b=0.7071*L-0.7071*M;\n",
        "    l = np.float64(l)\n",
        "    a = np.float64(a)\n",
        "    b = np.float64(b)\n",
        " \n",
        "    l1=0.5774*L1+0.5774*M1+0.5774*S1;\n",
        "    a1=0.4082*L1+0.4082*M1-0.8165*S1;\n",
        "    b1=0.7071*L1-0.7071*M1;\n",
        "    l1 = np.float64(l1)\n",
        "    a1 = np.float64(a1)\n",
        "    b1 = np.float64(b1)\n",
        " \n",
        "    I3 = cv2.merge((l,a,b))\n",
        "    A3 = cv2.merge((l1,a1,b1))\n",
        " \n",
        "    std1=std(l1);\n",
        "    std2=std(l);\n",
        " \n",
        "    std3=std(a1);\n",
        "    std4=std(a);\n",
        "    \n",
        "    std5=std(b1);\n",
        "    std6=std(b);\n",
        " \n",
        "    p=(sqrt(mean(l1))-(sqrt(mean(l))))/(sqrt(mean(l1))+(sqrt(mean(l))));   \n",
        "    s=0\n",
        "    if p>0:    \n",
        "        s=0.9-(0.9 - 0.15)/(1+exp((p-0.45)/(0.05)));\n",
        "    else:\n",
        "        s=0.15;\n",
        " \n",
        "    l2=mean(mean(l1))+(l-mean(mean(l)))*(1+s);\n",
        "    a2=mean(mean(a1))+(a-mean(mean(a)));\n",
        "    b2=mean(mean(b1))+(b-mean(mean(b)));\n",
        "    l2 = np.float64(l2)\n",
        "    a2 = np.float64(a2)\n",
        "    b2 = np.float64(b2)\n",
        " \n",
        "    l3=mean(mean(l1))+(l-mean(mean(l)))*(std1/std2);\n",
        "    a3=mean(mean(a1))+(a-mean(mean(a)))*(std3/std4);\n",
        "    b3=mean(mean(b1))+(b-mean(mean(b)))*(std5/std6);\n",
        "    l3 = np.float64(l3)\n",
        "    a3 = np.float64(a3)\n",
        "    b3 = np.float64(b3)\n",
        " \n",
        "    max_l=max(l2);\n",
        "    min_l=min(l2);\n",
        "    max_a=max(a2);\n",
        "    min_a=min(a2);\n",
        "    max_b=max(b2);\n",
        "    min_b=min(b2);\n",
        "  \n",
        "    I4 = cv2.merge((l2,a2,b2))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L2=0.5774*l2+0.4082*a2+0.7071*b2;\n",
        "    M2=0.5774*l2+0.4082*a2-0.7071*b2;\n",
        "    S2=0.5774*l2-0.8169*a2;\n",
        "    L2 = np.float64(L2)\n",
        "    M2 = np.float64(M2)\n",
        "    S2 = np.float64(S2)\n",
        " \n",
        "    R2=4.4679*L2-3.5873*M2+0.1193*S2;\n",
        "    G2=-1.2186*L2+2.3809*M2-0.1624*S2;\n",
        "    B2=0.0497*L2-0.2439*M2+1.2045*S2;\n",
        " \n",
        "    I5 = cv2.merge((R1, G2, B2))\n",
        "    I6 = cv2.merge((l3,a3,b3))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L3=0.5774*l3+0.4082*a3+0.7071*b3;\n",
        "    M3=0.5774*l3+0.4082*a3-0.7071*b3;\n",
        "    S3=0.5774*l3-0.8169*a3;\n",
        "    L3 = np.float64(L3)\n",
        "    M3 = np.float64(M3)\n",
        "    S3 = np.float64(S3)\n",
        " \n",
        "    R3=4.4679*L3-3.5873*M3+0.1193*S3;\n",
        "    G3=-1.2186*L3+2.3809*M3-0.1624*S3;\n",
        "    B3=0.0497*L3-0.2439*M3+1.2045*S3;\n",
        "    # R3 = np.float64(R3)\n",
        "    # G3 = np.float64(G3)\n",
        "    # B3 = np.float64(B3)\n",
        " \n",
        "    I7 = cv2.merge((R3,G3,B3))\n",
        "    I7 = normalize(I7)\n",
        "    return I7\n",
        "\n",
        "def preProcessing(img):\n",
        "    # Target = cv2.imread(train_path+'/0/IDRiD_061.jpg')\n",
        "    Target = cv2.imread('20051020_44782_0100_PP.tif')\n",
        "    Target = cv2.cvtColor(Target, cv2.COLOR_BGR2RGB)\n",
        "    Target = cv2.resize(Target, (400, 400))\n",
        "   # print(filename)\n",
        "   # img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    partA = -4 * cv2.GaussianBlur(img, (25,25), 0)\n",
        "    partB = 4*img + 0.5\n",
        "    result =  partB+partA\n",
        "    return normalize(result)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers, activations\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "print(\"Done Importing\")\n"
      ],
      "id": "d4023084",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Importing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "642d7e50",
        "outputId": "b4dff78b-e36b-40f5-92ee-521259c836f5"
      },
      "source": [
        ""
      ],
      "id": "642d7e50",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1613 images belonging to 2 classes.\n",
            "Found 103 images belonging to 2 classes.\n",
            "103/103 [==============================] - 22s 187ms/step - loss: 0.5838 - accuracy: 0.7767\n",
            "  7/101 [=>............................] - ETA: 4:39 - loss: 0.7148 - accuracy: 0.5982"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0c8991b12c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                         class_mode=\"categorical\")\n\u001b[1;32m     14\u001b[0m \u001b[0mmodelx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodelx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1706097f",
        "outputId": "5ba7e2ec-5867-48cc-c4ac-bf5958425e16"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from numpy import std, mean, sqrt, max, min, exp\n",
        "\n",
        "def normalize(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "# Color Transormation\n",
        "def ColorTransition(Simg, Timg):\n",
        "    R, G, B=cv2.split(Simg)\n",
        "    R = np.float64(R)\n",
        "    G = np.float64(G)\n",
        "    B = np.float64(B)\n",
        " \n",
        "    R1, G1, B1=cv2.split(Timg)\n",
        "    R1 = np.float64(R1)\n",
        "    G1 = np.float64(G1)\n",
        "    B1 = np.float64(B1)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Source Image\n",
        "    L=0.3811*R+0.5783*G+0.0402*B;\n",
        "    M=0.1967*R+0.7244*G+0.0782*B;\n",
        "    S=0.0241*R+0.1288*G+0.8444*B;\n",
        "    L = np.float64(L)\n",
        "    M = np.float64(M)\n",
        "    S = np.float64(S)\n",
        " \n",
        "    # conversion from RGB to lab color space -> Target Image\n",
        "    L1=0.3811*R1+0.5783*G1+0.0402*B1;\n",
        "    M1=0.1967*R1+0.7244*G1+0.0782*B1;\n",
        "    S1=0.0241*R1+0.1288*G1+0.8444*B1;\n",
        "    L1 = np.float64(L1)\n",
        "    M1 = np.float64(M1)\n",
        "    S1 = np.float64(S1)\n",
        " \n",
        "    I2 = cv2.merge((L,M,S))\n",
        "    A2 = cv2.merge((L1,M1,S1))\n",
        "    \n",
        "    l=0.5774*L+0.5774*M+0.5774*S;\n",
        "    a=0.4082*L+0.4082*M-0.8165*S;\n",
        "    b=0.7071*L-0.7071*M;\n",
        "    l = np.float64(l)\n",
        "    a = np.float64(a)\n",
        "    b = np.float64(b)\n",
        " \n",
        "    l1=0.5774*L1+0.5774*M1+0.5774*S1;\n",
        "    a1=0.4082*L1+0.4082*M1-0.8165*S1;\n",
        "    b1=0.7071*L1-0.7071*M1;\n",
        "    l1 = np.float64(l1)\n",
        "    a1 = np.float64(a1)\n",
        "    b1 = np.float64(b1)\n",
        " \n",
        "    I3 = cv2.merge((l,a,b))\n",
        "    A3 = cv2.merge((l1,a1,b1))\n",
        " \n",
        "    std1=std(l1);\n",
        "    std2=std(l);\n",
        " \n",
        "    std3=std(a1);\n",
        "    std4=std(a);\n",
        "    \n",
        "    std5=std(b1);\n",
        "    std6=std(b);\n",
        " \n",
        "    p=(sqrt(mean(l1))-(sqrt(mean(l))))/(sqrt(mean(l1))+(sqrt(mean(l))));   \n",
        "    s=0\n",
        "    if p>0:    \n",
        "        s=0.9-(0.9 - 0.15)/(1+exp((p-0.45)/(0.05)));\n",
        "    else:\n",
        "        s=0.15;\n",
        " \n",
        "    l2=mean(mean(l1))+(l-mean(mean(l)))*(1+s);\n",
        "    a2=mean(mean(a1))+(a-mean(mean(a)));\n",
        "    b2=mean(mean(b1))+(b-mean(mean(b)));\n",
        "    l2 = np.float64(l2)\n",
        "    a2 = np.float64(a2)\n",
        "    b2 = np.float64(b2)\n",
        " \n",
        "    l3=mean(mean(l1))+(l-mean(mean(l)))*(std1/std2);\n",
        "    a3=mean(mean(a1))+(a-mean(mean(a)))*(std3/std4);\n",
        "    b3=mean(mean(b1))+(b-mean(mean(b)))*(std5/std6);\n",
        "    l3 = np.float64(l3)\n",
        "    a3 = np.float64(a3)\n",
        "    b3 = np.float64(b3)\n",
        " \n",
        "    max_l=max(l2);\n",
        "    min_l=min(l2);\n",
        "    max_a=max(a2);\n",
        "    min_a=min(a2);\n",
        "    max_b=max(b2);\n",
        "    min_b=min(b2);\n",
        "  \n",
        "    I4 = cv2.merge((l2,a2,b2))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L2=0.5774*l2+0.4082*a2+0.7071*b2;\n",
        "    M2=0.5774*l2+0.4082*a2-0.7071*b2;\n",
        "    S2=0.5774*l2-0.8169*a2;\n",
        "    L2 = np.float64(L2)\n",
        "    M2 = np.float64(M2)\n",
        "    S2 = np.float64(S2)\n",
        " \n",
        "    R2=4.4679*L2-3.5873*M2+0.1193*S2;\n",
        "    G2=-1.2186*L2+2.3809*M2-0.1624*S2;\n",
        "    B2=0.0497*L2-0.2439*M2+1.2045*S2;\n",
        " \n",
        "    I5 = cv2.merge((R1, G2, B2))\n",
        "    I6 = cv2.merge((l3,a3,b3))\n",
        " \n",
        "    # Conversion from lab to RGB color space%\n",
        "    L3=0.5774*l3+0.4082*a3+0.7071*b3;\n",
        "    M3=0.5774*l3+0.4082*a3-0.7071*b3;\n",
        "    S3=0.5774*l3-0.8169*a3;\n",
        "    L3 = np.float64(L3)\n",
        "    M3 = np.float64(M3)\n",
        "    S3 = np.float64(S3)\n",
        " \n",
        "    R3=4.4679*L3-3.5873*M3+0.1193*S3;\n",
        "    G3=-1.2186*L3+2.3809*M3-0.1624*S3;\n",
        "    B3=0.0497*L3-0.2439*M3+1.2045*S3;\n",
        "    # R3 = np.float64(R3)\n",
        "    # G3 = np.float64(G3)\n",
        "    # B3 = np.float64(B3)\n",
        " \n",
        "    I7 = cv2.merge((R3,G3,B3))\n",
        "    I7 = normalize(I7)\n",
        "    return I7\n",
        "\n",
        "\n",
        "def preProcessing(img):\n",
        "    # Target = cv2.imread(train_path+'/0/IDRiD_061.jpg')\n",
        "    Target = cv2.imread('20051020_44782_0100_PP.tif')\n",
        "    Target = cv2.cvtColor(Target, cv2.COLOR_BGR2RGB)\n",
        "    Target = cv2.resize(Target, (400, 400))\n",
        "    img = ColorTransition(img, Target)\n",
        "    img = normalize(img)\n",
        "    partA = -4 * cv2.GaussianBlur(img, (25,25), 0)\n",
        "    partB = 4*img + 0.5\n",
        "    result = partA + partB\n",
        "    result = normalize(result)\n",
        "    return result\n",
        "\n",
        "modela=keras.models.load_model(\"best01.h5\")\n",
        "image_gen=ImageDataGenerator(preprocessing_function=preProcessing)\n",
        "train=image_gen.flow_from_directory(\"Dataset_12/TrainSet\",\n",
        "                                        target_size=(400, 400),\n",
        "                                        batch_size=16,\n",
        "                                        class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "test=image_gen.flow_from_directory(\"Dataset_12/TestSet\",\n",
        "                                       target_size=(400, 400),\n",
        "                                        batch_size=1,\n",
        "                                        class_mode=\"categorical\")\n",
        "modela.evaluate(test)\n",
        "modela.evaluate(train)\n",
        "\n"
      ],
      "id": "1706097f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 462 images belonging to 2 classes.\n",
            "Found 58 images belonging to 2 classes.\n",
            "58/58 [==============================] - 15s 210ms/step - loss: 0.2966 - accuracy: 0.8793\n",
            "29/29 [==============================] - 63s 2s/step - loss: 0.3037 - accuracy: 0.8701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30365505814552307, 0.8701298832893372]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29a40f9e"
      },
      "source": [
        ""
      ],
      "id": "29a40f9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3447da39"
      },
      "source": [
        ""
      ],
      "id": "3447da39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmizTaONdHuT",
        "outputId": "14804160-4fc4-49f3-e8be-57ba9e4ffea7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "OmizTaONdHuT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqNyMRvpdKJQ"
      },
      "source": [
        ""
      ],
      "id": "BqNyMRvpdKJQ",
      "execution_count": null,
      "outputs": []
    }
  ]
}